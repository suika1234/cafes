{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import csv\n",
    "from typing import List, Dict\n",
    "import time\n",
    "\n",
    "async def scrape_google_maps_reviews_async(url: str, max_reviews: int = 20) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Scrape reviews from a Google Maps location URL.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The Google Maps URL of the location\n",
    "        max_reviews (int): Maximum number of reviews to scrape\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: List of review dictionaries containing reviewer, rating, text, and date\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "        \n",
    "        try:\n",
    "            # Navigate to the page and wait for it to load\n",
    "            await page.goto(url)\n",
    "            await page.wait_for_load_state('networkidle')\n",
    "            await page.wait_for_timeout(5000)  # Give more time for initial load\n",
    "            \n",
    "            # First, try to find and click the reviews button\n",
    "            try:\n",
    "                # Try different selectors for the reviews button\n",
    "                review_button_selectors = [\n",
    "                    'button[aria-label*=\"Reviews\"]',\n",
    "                    'button[aria-label*=\"reviews\"]',\n",
    "                    'button[jsaction*=\"pane.reviewChart\"]',\n",
    "                    'button[data-tab-index=\"1\"]'\n",
    "                ]\n",
    "                \n",
    "                for selector in review_button_selectors:\n",
    "                    try:\n",
    "                        reviews_button = await page.wait_for_selector(selector, timeout=3000)\n",
    "                        if reviews_button:\n",
    "                            await reviews_button.click()\n",
    "                            await page.wait_for_timeout(3000)\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "            except Exception as e:\n",
    "                print(\"‚ö†Ô∏è Could not click reviews button - might already be on reviews tab\")\n",
    "            \n",
    "            # Wait for the reviews panel to load\n",
    "            await page.wait_for_timeout(5000)\n",
    "            \n",
    "            # Try to find the reviews panel with multiple selectors\n",
    "            review_panel_selectors = [\n",
    "                'div[aria-label*=\"Reviews\"]',\n",
    "                'div[class*=\"m6QErb\"]',\n",
    "                'div[class*=\"dS8AEf\"]',\n",
    "                'div[class*=\"review-dialog-list\"]',\n",
    "                'div[class*=\"review-panel\"]',\n",
    "                'div[class*=\"review-list\"]',\n",
    "                'div[class*=\"reviews\"]'\n",
    "            ]\n",
    "            \n",
    "            review_panel = None\n",
    "            for selector in review_panel_selectors:\n",
    "                try:\n",
    "                    review_panel = await page.wait_for_selector(selector, timeout=3000)\n",
    "                    if review_panel:\n",
    "                        print(f\"‚úÖ Found review panel with selector: {selector}\")\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if not review_panel:\n",
    "                print(\"‚ùå Could not find review panel\")\n",
    "                # Take a screenshot for debugging\n",
    "                await page.screenshot(path=\"debug_screenshot.png\")\n",
    "                return results\n",
    "            \n",
    "            # Scroll to load more reviews\n",
    "            last_height = 0\n",
    "            scroll_attempts = 0\n",
    "            max_scroll_attempts = 20\n",
    "            \n",
    "            while scroll_attempts < max_scroll_attempts:\n",
    "                # Scroll within the review panel\n",
    "                await review_panel.evaluate('el => el.scrollBy(0, el.scrollHeight)')\n",
    "                await page.wait_for_timeout(2000)\n",
    "                \n",
    "                # Check if we've reached the bottom\n",
    "                new_height = await review_panel.evaluate('el => el.scrollHeight')\n",
    "                if new_height == last_height:\n",
    "                    scroll_attempts += 1\n",
    "                else:\n",
    "                    scroll_attempts = 0\n",
    "                last_height = new_height\n",
    "                \n",
    "                # Check if we have enough reviews\n",
    "                review_elements = await page.query_selector_all('div[class*=\"jftiEf\"]')\n",
    "                if len(review_elements) >= max_reviews:\n",
    "                    break\n",
    "            \n",
    "            # Extract reviews\n",
    "            review_elements = await page.query_selector_all('div[class*=\"jftiEf\"]')\n",
    "            print(f\"üîç Found {len(review_elements)} review elements\")\n",
    "            \n",
    "            for review in review_elements[:max_reviews]:\n",
    "                try:\n",
    "                    # Expand review text if there's a \"More\" button\n",
    "                    more_button = await review.query_selector('button[class*=\"w8nwRe\"]')\n",
    "                    if more_button:\n",
    "                        await more_button.click()\n",
    "                        await page.wait_for_timeout(1000)\n",
    "                    \n",
    "                    # Extract review data with multiple selector attempts\n",
    "                    name = await review.query_selector('div[class*=\"d4r55\"]')\n",
    "                    rating = await review.query_selector('span[class*=\"kvMYJc\"]')\n",
    "                    text = await review.query_selector('span[jsname=\"bN97Pc\"]')\n",
    "                    date = await review.query_selector('span[class*=\"rsqaWe\"]')\n",
    "                    \n",
    "                    if all([name, rating, text, date]):\n",
    "                        review_data = {\n",
    "                            \"reviewer\": await name.inner_text(),\n",
    "                            \"rating\": await rating.get_attribute('aria-label'),\n",
    "                            \"text\": await text.inner_text(),\n",
    "                            \"date\": await date.inner_text()\n",
    "                        }\n",
    "                        results.append(review_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error extracting review: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during scraping: {str(e)}\")\n",
    "        finally:\n",
    "            await browser.close()\n",
    "    \n",
    "    # Save results to CSV\n",
    "    if results:\n",
    "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f'google_reviews_{timestamp}.csv'\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"reviewer\", \"rating\", \"text\", \"date\"])\n",
    "            writer.writeheader()\n",
    "            writer.writerows(results)\n",
    "        print(f\"‚úÖ Saved {len(results)} reviews to '{filename}'\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No reviews found to save.\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error during scraping: Timeout 30000ms exceeded.\n",
      "‚ö†Ô∏è No reviews found to save.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await scrape_google_maps_reviews_async(\n",
    "    \"https://www.google.com/maps/place/Starbucks+Coffee+-+Shibuya+Tsutaya+1F/@35.6598742,139.6977439,17z/data=!3m1!4b1!4m6!3m5!1s0x60188dff9153f0dd:0x231e1baa5a961254!8m2!3d35.6598699!4d139.7003242!16s%2Fg%2F11vz3knlxc?entry=ttu&g_ep=EgoyMDI1MDQyOS4wIKXMDSoASAFQAw%3D%3D\",\n",
    "    max_reviews=30\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
